import whisper
import torch
import os

# æ£€æŸ¥ PyTorch æ˜¯å¦ä½¿ç”¨ CPU
print("\nğŸ” æ£€æŸ¥ PyTorch ç‰ˆæœ¬...")
print("PyTorch ç‰ˆæœ¬:", torch.__version__)
print("CUDA æ˜¯å¦å¯ç”¨:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("CUDA ç‰ˆæœ¬:", torch.version.cuda)
    print("å½“å‰ GPU:", torch.cuda.get_device_name(0))
else:
    print("âŒ CUDA ä¸å¯ç”¨ï¼ŒWhisper åªèƒ½ä½¿ç”¨ CPU è¿è¡Œï¼")

# ç¡®ä¿éŸ³é¢‘æ–‡ä»¶å­˜åœ¨
audio_file = r"H:\StoryBot\backend\test.mp3"
if not os.path.exists(audio_file):
    print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
    exit()
else:
    print(f"âœ… æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶: {audio_file}")

# åŠ è½½ Whisper æ¨¡å‹
def transcribe_audio(audio_path, model_size="small"):
    print("\nğŸ” åŠ è½½ Whisper æ¨¡å‹...")
    model = whisper.load_model(model_size)
    print(f"âœ… Whisper {model_size} æ¨¡å‹åŠ è½½æˆåŠŸï¼")

    print("\nğŸ™ï¸ è½¬å½•éŸ³é¢‘...")
    result = model.transcribe(audio_path, fp16=False)
    print("âœ… è½¬å½•å®Œæˆï¼")
    print("\nğŸ“ è¯†åˆ«æ–‡æœ¬:")
    print(result["text"])

# è¿è¡Œè¯­éŸ³è½¬å½•
transcribe_audio(audio_file, model_size="small")